---
title: "Identifying predictors of postoperative blood-related health complications"
subtitle: "JSC370H1 - Final Project"
author: "Ryan Shi"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
urlcolor: blue
---

\newpage

<!-- Links to the database webpages: -->
<!-- https://data.cms.gov/provider-data/sites/default/files/data_dictionaries/hospital/HOSPITAL_Data_Dictionary.pdf -->
<!-- https://data.cms.gov/provider-data/dataset/77hc-ibv8 -->
<!-- https://data.cms.gov/provider-data/dataset/yv7e-xc69 -->
<!-- https://data.cms.gov/provider-data/dataset/ynj2-r877 -->

```{r, include = FALSE, message = FALSE, warning = FALSE}
# install.packages(c("leaflet", "reshape2", "patchwork", "kableExtra", "randomForest", "xgboost", "caret"))
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(patchwork)
library(kableExtra)
library(MASS)
library(randomForest)
library(xgboost)
library(caret)

# Note: these direct links might change from time to time; refer to the database webpages listed above
hai <- read_csv("https://data.cms.gov/provider-data/sites/default/files/resources/05819383a875a1ebce5ed5f28755558b_1712462723/Healthcare_Associated_Infections-Hospital.csv")
tec <- read_csv("https://data.cms.gov/provider-data/sites/default/files/resources/350f34f9ef3d484925d49dfcce7a0f54_1712462752/Timely_and_Effective_Care-Hospital.csv")
cd <- read_csv("https://data.cms.gov/provider-data/sites/default/files/resources/1818d71cb5d94636b87ed8459af818d6_1712462715/Complications_and_Deaths-Hospital.csv")

select <- dplyr::select
theme_set(theme_minimal())
```

```{r, include = FALSE, message = FALSE, warning = FALSE}
columns_to_exclude <- c("Facility Name", "Address", "City/Town", "ZIP Code", "County/Parish", "Telephone Number", "Condition", "Measure Name", "Compared to National", "Lower Estimate", "Higher Estimate", "Sample", "Footnote", "Start Date", "End Date")

# Remove certain columns, remove certain measures, reshape tables

infections <- hai[, !(names(hai) %in% columns_to_exclude)] |>
  filter(!grepl("CILOWER", `Measure ID`)
         & !grepl("CIUPPER", `Measure ID`)
         & !grepl("ELIGCASES", `Measure ID`)
         & !grepl("SIR", `Measure ID`)
         & !grepl("HAI_2", `Measure ID`)
         & !grepl("HAI_3", `Measure ID`)
         & !grepl("HAI_4", `Measure ID`)
         & !grepl("HAI_6", `Measure ID`)) |>
  pivot_wider(names_from = `Measure ID`,
              values_from = Score) |>
  transform(HAI_1_NUMERATOR = as.numeric(HAI_1_NUMERATOR),
            HAI_1_DOPC = as.numeric(HAI_1_DOPC),
            HAI_5_NUMERATOR = as.numeric(HAI_5_NUMERATOR),
            HAI_5_DOPC = as.numeric(HAI_5_DOPC)) |>
  mutate(central_line = 100 * HAI_1_NUMERATOR / HAI_1_DOPC,
         staph = 100 * HAI_5_NUMERATOR / HAI_5_DOPC) |>
  rename(facility_id = `Facility.ID`, state = State) |>
  select(facility_id, state, central_line, staph)

timely <- tec[, !(names(tec) %in% columns_to_exclude)] |>
  filter(`Measure ID` %in% c("EDV", "IMM_3", "HCP_COVID_19")) |>
  pivot_wider(names_from = `Measure ID`,
              values_from = Score) |>
  rename(facility_id = `Facility ID`, state = State, ed_vol = EDV,
         covid_vac = HCP_COVID_19, flu_vac = IMM_3) |>
  transform(covid_vac = as.numeric(covid_vac),
            flu_vac = as.numeric(flu_vac))

deaths <- cd[, !(names(cd) %in% columns_to_exclude)] |>
  filter(`Measure ID` %in% c("PSI_09", "PSI_12", "PSI_13")) |>
  pivot_wider(names_from = `Measure ID`,
              values_from = c(Score, Denominator)) |> 
  rename(facility_id = `Facility ID`, state = State,
         hem = Score_PSI_09, clot = Score_PSI_12,
         stream = Score_PSI_13, hem_denom = Denominator_PSI_09,
         clot_denom = Denominator_PSI_12,
         stream_denom = Denominator_PSI_13) |> 
  transform(hem = as.numeric(hem), clot = as.numeric(clot),
            stream = as.numeric(stream),
            hem_denom = as.numeric(hem_denom),
            clot_denom = as.numeric(clot_denom),
            stream_denom = as.numeric(stream_denom)) |> 
  mutate(hem_count = round(hem * hem_denom / 100),
         clot_count = round(clot * clot_denom / 100),
         stream_count = round(stream * stream_denom / 100))

# Format NA values, remove rows with all NAs, count NAs

infections[infections == "Not Available"] <- NA
timely[timely == "Not Available"] <- NA
deaths[deaths == "Not Available"] <- NA
infections <- infections[!is.na(infections$central_line) | !is.na(infections$staph),]
timely <- timely[!is.na(timely$ed_vol) | !is.na(timely$covid_vac) | !is.na(timely$flu_vac),]
deaths <- deaths[!is.na(deaths$hem) | !is.na(deaths$clot) | !is.na(deaths$stream),]
# sapply(infections, function(y) mean(is.na(y)))
# sapply(timely, function(y) mean(is.na(y)))
# sapply(deaths, function(y) mean(is.na(y)))

# Join the tables, remove remaining NAs, remove outliers

merged <- merge(x = infections, y = timely,
                by = c("facility_id", "state"))
merged <- merge(x = merged, y = deaths,
                by = c("facility_id", "state"))
merged <- merged[complete.cases(merged),]
merged <- merged[merged$central_line <= 0.50,]
merged <- merged[merged$hem <= 6,]
merged <- merged[merged$clot <= 7,]
merged <- merged[merged$stream <= 12,]
```

```{r, include = FALSE, eval = FALSE}
summary(merged)
merged |> group_by(ed_vol) |> count()
ggplot(merged, aes(x = central_line)) + geom_histogram()
merged |> filter(central_line > 0.5) |> count()
merged |> filter(central_line == 0) |> count() / merged |> filter(central_line > 0) |> count()
ggplot(merged, aes(x = staph)) + geom_histogram()
merged |> filter(staph == 0) |> count() / merged |> filter(staph > 0) |> count()
ggplot(merged, aes(x = hem)) + geom_histogram()
merged |> filter(hem > 6) |> count()
ggplot(merged, aes(x = clot)) + geom_histogram()
merged |> filter(clot > 7) |> count()
ggplot(merged, aes(x = stream)) + geom_histogram()
merged |> filter(stream > 12) |> count()
ggplot(merged, aes(x = hem_count)) + geom_histogram()
merged |> filter(hem_count > 300) |> count()
```

# Introduction

Health complications following surgery, or postoperative health complications, often pose problems to treatment efficacy and contribute to higher healthcare costs (Dencker et al. 2021). Potential factors for them include hospital-acquired infections or healthcare-associated infections (HAI), which are common in hospitals and can increase morbidity and mortality in patients (Kanerva et al. 2008). Other factors that may influence treatment include staff vaccination rates (Hollmeyer et al. 2012) and emergency department (ED) volume (Brar et al. 2013). Identifying the specific infections and factors that correlate with the greatest increase in postoperative health complications will inform initiatives of hospitals to improve their quality and efficiency of care.

For 5424 hospitals registered with Medicare in the U.S., the [Centers for Medicare & Medicaid Services](https://www.cms.gov) have collected data regarding HAI, ED volume, staff vaccination rates, and complications and mortality rates.

- The [Healthcare Associated Infections - Hospital](https://data.cms.gov/provider-data/dataset/77hc-ibv8) dataset (dataset 1) records the number of cases in each hospital for six common sources of infections: central venous catheters (central lines), urinary tract catheters, surgical site infection from colon surgery, surgical site infection from abdominal hysterectomy, Methicillin-resistant *Staphylococcus aureus* (*S. aureus* or staph) bacteria, and *Clostridium difficile* (*C. diff*) bacteria. The values are cumulative from 04/01/2022 to 03/31/2023.

- The [Timely and Effective Care - Hospital](https://data.cms.gov/provider-data/dataset/yv7e-xc69) dataset (dataset 2) includes various metrics, such as the average time patients spent in ED and rates of septic shock. The metrics of interest here are the ED volume and staff vaccination rates for COVID and the flu, all per hospital. The values are cumulative from 01/01/2022 to 12/31/2022.

- The [Complications and Deaths - Hospital](https://data.cms.gov/provider-data/dataset/ynj2-r877) dataset (dataset 3) records various rates of complications and rates of death per hospital, such as for post-surgery wound dehiscence, post-surgery respiratory failure, and collapsed lung. The values are cumulative from 07/01/2020 to 06/30/2022.

The question to be explored is, "Can hospital-acquired blood infections, ED volumes, and / or staff vaccination rates reliably predict postoperative blood-related complication rates in Medicare hospitals?" My current hypothesis is that a subset of the variables can reliably predict complication rates after surgery. In addition, I hypothesize that all but vaccination rates positively correlate with postoperative blood-related complications. This is since infections would increase the risk of complications occurring and higher ED volumes would lead to more sources of contamination, while increased vaccination might reduce transmissions of infections from staff to patients. I also aim to investigate how these relations vary across states.

# Methods

## Variables

For sources of hospital-acquired blood infections, which is a predictor in my question, I chose to look at central lines and the staph bacteria since they affect the bloodstream directly. I did not look at the other sources of infections recorded by the datasets since they do not affect the bloodstream directly, instead implicating parts of the abdomen such as the colon and urinary tract.

For postoperative blood-related complication rates, which is the outcome in my question, I chose to look at hemorrhage / hematoma events (loss of blood from damaged blood vessels), serious blood clots, and bloodstream infections since they are common complications and affect blood cells and vessels. I did not look at the other complications recorded by the datasets since they do not relate to blood, instead implicating the respiratory system and epithelial tissues.

Thus, I will use the following variables for my analysis:

```{r, echo = FALSE}
data.frame(
  Variable = c("central_line", "staph", "ed_vol", "covid_vac",
               "flu_vac", "hem", "clot", "stream"),
  Definition = c("Percent of infections from central lines",
                 "Percent of infections from the staph bacteria",
                 "Level of ED volume (very high, high, medium, or low)",
                 "Percent of hospital staff vaccinated against COVID",
                 "Percent of staff vaccinated against the flu",
                 "Percent of postoperative hemorrhage/hematoma events",
                 "Percent of postoperative serious blood clots",
                 "Percent of postoperative bloodstream infections"),
  Dataset = c("Dataset 1", "Dataset 1", "Dataset 2", "Dataset 2",
              "Dataset 2", "Dataset 3", "Dataset 3", "Dataset 3")) |> 
  kable() |>
  pack_rows("Predictors", 1, 5) |>
  pack_rows("Outcomes", 6, 8)
```

## Acquiring the datasets

I acquired the datasets by extracting their links to their CSV files from the network activity of their pages and directly loading those files. This was because I did not manage to extract the data from the JSON file which the API provided. Dataset 1 has 173232 rows, dataset 2 has 115498 rows, and dataset 3 has 91428 rows. All three datasets has 20 columns and are in long format, where each hospitals has multiple rows for different measures (e.g., rates of infections). For each of them, I excluded uninformative or redundant columns such as facility name, address, phone number, and measure name, while I kept columns such as facility ID, state, measure ID, and the value for the measure. I did not encounter import issues with the datasets, except that I had to convert some columns from character to numeric form.

## Preparing the datasets

For dataset 1, I kept rows measuring the number of central line and staph infections, which are predictors. I reshaped the table such that each measure occupied a separate column, and I calculated the percents of infection using the counts of infection and the number of operations involving the source of infection per hospital, which are provided in the dataset. I renamed the predictors as `central_line` and `staph` respectively, and selected their columns along with the facility ID and state.

For dataset 2, I kept rows measuring ED volumes and percents of vaccination among staff, which are predictors. Since the dataset already classified the ED volumes into four levels, I was not able to obtain the exact counts of the volumes. I reshaped the table, renamed the predictors as `ed_vol`, `covid_vac`, and `flu_vac` respectively, and selected their columns along with the facility ID and state.

For dataset 3, I kept rows measuring percents of postoperative hemorrhage/hematoma, serious blood clots, and bloodstream infection, which are the outcomes. I also calculated the counts corresponding to these percents using the total number of operations for each hospital, which will be used in the regression analysis. I reshaped the table, renamed the outcomes as `hem`, `clot`, and `stream` respectively, and selected their columns along with the facility ID and state.

## Missing values

Before joining the datasets, I replaced all values of "Not Available" with NA, and I removed all rows which had no values recorded for any measures. I then investigated the proportion of missing values for each dataset:

- In dataset 1, the rates of central line and staph infections are 9.26% and 5.21% missing respectively.
- In dataset 2, the ED volumes and rates of vaccinations are 11.3%, 15.5%, and 4.45% missing respectively.
- In dataset 3, the rates of postoperative hemorrhage, blood clots, and bloodstream infection are 1.70%, 0.00%, and 13.2% respectively.

Since I did not deem these proportions of missing values to be significant, I joined the datasets and removed all rows with missing values, leaving 2248 rows with 16 columns in wide format.

## Outliers and implausible values

Looking at the distribution of each variable, I did not find outliers or implausible values for `staph`, `ed_vol`, `covid_vac`, and `flu_vac`. For the other variables:

- `central_line`: Most values are between 0% and 35%. I removed 3 outliers with values greater than 50%.
- `hem`: Most values are between 1% and 4%. I removed 1 outlier with value greater than 6%.
- `clot`: Most values are between 1% and 6%. I removed 1 outlier with value greater than 7%.
- `stream`: Most values are between 1% and 10%. I removed 1 outlier with value greater than 12%.

For `central_line` and `staph`, 37.8% and 44.2% of their values are 0%. These points may skew my overall results, but since they make up a large proportion of the values, I did not remove them entirely. Instead, I only removed them temporarily in some exploratory graphs for clarity.

## Tools used

For data exploration, I created:

- A table showing the summary statistics of the numeric variables using `kable` and `kable_styling` from kableExtra;
- Six histograms of the outcomes as rates and counts using `geom_histogram` from ggplot2 and `plot_layout` from patchwork;
- A heatmap of pairwise correlations between the numeric variables using `melt` from reshape2 and `geom_tile` and `geom_text` from ggplot2;
- Three pairs of choropleth maps showing the means of selected numeric variables by state using `plot_geo` from plot_ly;
- Three boxplots of the outcomes grouped by ED volume using `geom_boxplot` from ggplot2 and `plot_layout` from patchwork;
- Three scatterplots of the log-transformed outcomes vs `flu_vac`, `covid_vac`, and `staph` grouped by ED volume using `geom_point` and `geom_smooth` from ggplot2 and `plot_layout` from patchwork.

For regression analysis, I performed Poisson and negative binomial regression using `glm` from the stats package and `glm.nb` from MASS.

For the machine learning models, I created bagging, random forest, and XGBoost models using `randomForest` from randomForest and `train` from caret. For the bagging models, I set the 'mtry' hyperparameter in `randomForest` to 5, which is the number of predictors for each outcome. For the XGBoost models, I performed grid search on various hyperparameters in `train`, such as 1, 3, 5, and 7 for 'max_depth' and 0.001, 0.01, 0.1, and 0.2 for 'eta'.

# Results

## Exploratory data analysis

```{r, echo = FALSE}
merged_summary <- merged |>
  select(3, 4, 6, 7, 8, 9, 10) |>
  lapply(function(x) { round(summary(x), 4) })

merged_summary <- as.data.frame(do.call(rbind, merged_summary))
rownames(merged_summary) <- c("Central line infection", "Staph infection", "COVID vaccination", "Flu vaccination", "Hemorrhage/hematoma", "Serious blood clots", "Bloodstream infection")

kable(merged_summary, caption = "Summary of the numeric variables (as rates)") |> 
  pack_rows("Predictors", 1, 4) |> 
  pack_rows("Outcomes", 5, 7)
```

First, I explore the distributions of the numeric variables. Table 2 shows that the rates of central line and staph infections are very skewed towards 0%, meaning these infections rarely occur in hospitals. This agrees with my previous finding that 37.8% and 44.2% of `central_line` and `staph` respectively are 0%. Both vaccination rates are skewed towards 100%, indicating that hospitals are generally successful in encouraging vaccination among their workers. Finally, the outcome variables are all skewed towards 0%, meaning postoperative blood-related complications are generally uncommon. Of these variables, the rate of postoperative bloodstream infections is the largest across all listed metrics, indicating that it is relatively more common than the other outcomes.

To further explore their distributions, I now look at the outcome variables both as rates and as counts of postoperative complications.

```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.align = 'center', out.width = "75%"}
ggplot(merged, aes(x = hem)) +
  geom_histogram() +
  labs(x = "Hemorrhage / hematoma rate", y = "Count") +
ggplot(merged, aes(x = clot)) +
  geom_histogram() +
  labs(x = "Serious blood clot rate", y = "Count") +
ggplot(merged, aes(x = stream)) +
  geom_histogram() +
  labs(x = "Bloodstream infection rate", y = "Count") +
  plot_layout(nrow = 3) +
  plot_annotation(title = "Distributions of the outcome variables (as rates)")

ggplot(merged, aes(x = hem_count)) +
  geom_histogram(bins = 50) +
  xlim(0, 200) +
  labs(x = "# of hemorrhage / hematoma events", y = "Count") +
ggplot(merged, aes(x = clot_count)) +
  geom_histogram(bins = 50) +
  xlim(0, 300) +
  labs(x = "# of serious blood clot events", y = "Count") +
ggplot(merged, aes(x = stream_count)) +
  geom_histogram(bins = 50) +
  xlim(0, 200) +
  labs(x = "# of bloodstream infection events", y = "Count") +
  plot_layout(nrow = 3) +
  plot_annotation(title = "Distributions of the outcome variables (as numbers of events)")
```

From the above histograms, the rates appear to be normally distributed with slightly longer right tails, while the counts of events appear to be Poisson distributed with no obvious upper bounds. This suggests that compared to linear regression, Poisson or negative binomial regression might be more suitable to model postoperative complications, which will be performed later on.

Next, I explore the pairwise correlations between the numeric variables.

```{r, echo = FALSE, fig.align = "center", out.width = "75%"}
# Pairwise correlation heatmap

merged |>
  select(3, 4, 6, 7, 8, 9, 10) |>
  cor() |>
  melt() |>
  ggplot(aes(x = Var1, y = Var2)) +
  geom_tile(aes(fill = value)) +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(low = "blue", high = "red") +
  labs(title = "Heatmap of pairwise correlations between the numeric variables", fill = "Correlation") +
  theme(axis.title = element_blank())
```

The heatmap above shows that overall, there is little correlation between the predictors (`central_line`, `staph`, `covid_vac`, `flu_vac`) and the outcomes (`hem`, `clot`, `stream`), with most coefficients being between 0 and 0.1. Among all pairs of predictors and outcomes, the pairs `flu_vac` and `hem`, `covid_vac` and `clot`, and `staph` and `stream` have the greatest coefficients, with values 0.12, 0.11, and 0.11 respectively. This suggests that `flu_vac`, `covid_vac`, and `staph` are likely to be the most significant predictors of these response variables. Interestingly, with a coefficient of 0.37, there appears to be collinearity between both rates of vaccination, suggesting that hospital staff tend to be vaccinated against multiple pathogens at the same time. As well, with a coefficient of 0.28, there appears to be collinearity between `central_line` and `staph`, suggesting that these healthcare-acquired infections likely occur together.

Since `flu_vac` and `hem`, `covid_vac` and `clot`, and `staph` and `stream` appear to be correlated in the heatmap, I now explore their relationships across states using the three pairs of cloropleth maps (shown [here](https://ryancys1234.github.io/JSC370-Project/visualizations.html#Mean_values_of_selected_numeric_variables_by_state)):

- For the first pair of maps, `flu_vac` and `hem` appear to have a slight negative relationship across states. Several states with lower rates of flu vaccinations among hospital staff, such as Arkansas and Wiscousin, have higher rates of postoperative hemorrhage / hematoma. Conversely, several states with higher rates of flu vaccinations among hospital staff, such as Maine and Maryland, have lower rates of postoperative hemorrhage / hematoma.

- For the second pair of maps, `covid_vac` and `clot` appear to have a negative relationship across states. Notably, states in New England have high rates of COVID vaccination among hospital staff and low rates of postoperative serious blood clots, while multiple southern states have low rates of COVID vaccination among hospital staff and high rates of postoperative serious blood clots.

- For the third pair of maps, `staph` and `stream` appear to have a slight negative relationship across states. Several states with high mean rates of hospital-acquired staph infections, such as West Virginia and Louisiana, have low mean rates of postoperative bloodstream infections. However, the relationship between the variables is weak since rates of postoperative bloodstream infections appear to be roughly uniform across states.

Overall, the pairs of variables appear to have negative relationships across states, which is intriguing since in the heatmap, they are positively correlated without grouping by state. This is more intuitive for the first two pairs of variables, since hospitals with a high proportion of vaccinated workers are likely more careful when handling potential sources of health hazards. Thus, states with these hospitals are likely to have fewer postoperative complications overall.

Next, I explore the relationship between ED volume and the numeric variables.

```{r, echo = FALSE, fig.align = "center", out.width = "75%"}
merged |>
  mutate(ed_vol = factor(ed_vol, levels = c("low", "medium", "high",
                                            "very high"))) |>
  ggplot(aes(x = ed_vol, y = hem, color = ed_vol)) +
  geom_boxplot() +
  labs(x = "ED volume", y = "Hemorrhage / hematoma rate") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, vjust = 0.5,
                                   hjust = 1)) +
merged |>
  mutate(ed_vol = factor(ed_vol, levels = c("low", "medium", "high",
                                            "very high"))) |>
  ggplot(aes(x = ed_vol, y = clot, color = ed_vol)) +
  geom_boxplot() +
  labs(x = "ED volume", y = "Serious blood clot rate") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, vjust = 0.5,
                                   hjust = 1)) +
merged |>
  mutate(ed_vol = factor(ed_vol, levels = c("low", "medium", "high",
                                            "very high"))) |>
  ggplot(aes(x = ed_vol, y = stream, color = ed_vol)) +
  geom_boxplot() +
  labs(x = "ED volume", y = "Bloodstream infection rate") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, vjust = 0.5,
                                   hjust = 1)) +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Outcome variables by ED volume")
```

For all three outcomes, the above boxplots show that the distributions become wider and more dispersed as ED volume increases. This makes sense since hospitals with higher ED volumes might have more potential sources of infection. As well, during periods of high ED volumes, hospital workers might be more variable in their attention to health hazards since they likely to be busier and more overworked.

Since I suspect heteroskedasticity in the outcomes when grouping by ED volume, I apply a logarithmic transformation to the outcomes for the following scatterplots. As before, I choose to explore the relationships between `flu_vac` and `hem`, `covid_vac` and `clot`, and `staph` and `stream` since they have the largest correlations of any pair of predictors and outcomes in the heatmap.

```{r, echo = FALSE, fig.align = "center", out.width = "75%"}
merged |>
  mutate(log_hem = log(hem)) |>
  ggplot(aes(x = flu_vac, y = log_hem, color = ed_vol)) +
  geom_point(size = .5) +
  geom_smooth(formula = 'y ~ x', method = "lm", se = FALSE,
              linewidth = .75) +
  labs(x = "Flu vaccination rate",
       y = "Log of hemorrhage/hematoma rate") +
  theme(legend.position = "none") +
merged |>
  mutate(log_clot = log(clot)) |>
  ggplot(aes(x = covid_vac, y = log_clot, color = ed_vol)) +
  geom_point(size = .5) +
  geom_smooth(formula = 'y ~ x', method = "lm", se = FALSE,
              linewidth = .75) +
  labs(x = "COVID vaccination rate",
       y = "Log of serious blood clot rate") +
  theme(legend.position = "none") +
merged |>
  mutate(log_stream = log(stream)) |>
  filter(staph > 0) |>
  ggplot(aes(x = staph, y = log_stream, color = ed_vol)) +
  geom_point(size = .5) +
  geom_smooth(formula = 'y ~ x', method = "lm", se = FALSE,
              linewidth = .75) +
  labs(x = "Staph infection rate",
       y = "Log of bloodstream infection rate",
       color = "ED volume") +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Log of outcome variables vs selected predictors by ED volume")
```

In the above scatterplots, the relationships for all three pairs of variables are positive for all ED volumes, which agrees with the positive correlations in the heatmap. Moreover, these relationships are the most significant when ED volume is 'very high', since the regression lines for the group are the steepest. Nevertheless, these relationships are weak overall since the transformed outcomes still appear to be overly dispersed, which means that the transformations likely do not yield significant changes in the relationships between the variables. Thus, the outcomes will not be transformed for the subsequent analyses.

## Regression analysis

I will use generalized linear models (e.g., Poisson regression) since the outcomes are expressed in rates, which are calculated using counts of postoperative complications out of the total number of operations for each hospital. Thus, the response variables in the models will be the counts, while the offset terms will be the total number of operations for each hospital.

First, I perform Poisson regression on `hem_count ~ central_line + staph + ed_vol + covid_vac + flu_vac + offset(log(total))`, where `hem_count` is the number of postoperative hemorrhage / hematoma events for each hospital and `log(total)` is the offset. However, this model is a poor fit to the data since its standardized residuals (not shown) appear to be overdispersed. In addition, `flu_vac` is the only significant predictor in the model, with a corresponding P-value of 5.49e-16 < 0.001. Thus, instead of Poisson regression, I perform negative binomial regression on `hem_count ~ flu_vac + offset(log(total))`.

```{r, echo = FALSE}
# summary(glm(data = merged, formula = hem_count ~ central_line + staph + ed_vol + covid_vac + flu_vac + offset(log(hem_denom)), family = poisson))

coef1 <- coef(summary(glm.nb(hem_count ~ flu_vac + offset(log(hem_denom)), merged)))
colnames(coef1) <- c("Estimate", "Std. error", "z-value", "P-value")
kable(coef1, caption = "Negative binomial regression summary for $hem$ vs $flu\\_vac$")
```

In the above table, the summary shows that for every increase of 1% in the rate of flu vaccinations among staff in a hospital, the logarithm of the expected number of postoperative hemorrhage / hematoma events increases by 0.0017. In other words, the expected number of postoperative hemorrhage / hematoma events increases by a factor of $\exp(0.0017) = 1.0017$. The P-value of the predictor is 1e-07 < 0.001, indicating significance. The AIC of the current model (13534) is lower than the AIC of the corresponding Poisson model (15357), indicating the current model better fits the data.

Next, I perform Poisson regression on `clot_count ~ central_line + staph + ed_vol + covid_vac + flu_vac + offset(log(total))`, where `clot_count` is the number of postoperative serious blood clot events for each hospital and `log(total)` is the offset. However, as before, the standardized residuals of the model appear to be overdispersed. In addition, `covid_vac` is the only significant predictor in the model, with a corresponding P-value of 2e-16 < 0.001. Thus, instead of Poisson regression, I perform negative binomial regression on `clot_count ~ covid_vac + offset(log(total))`.

```{r, echo = FALSE}
# summary(glm(data = merged, formula = clot_count ~ central_line + staph + ed_vol + covid_vac + flu_vac, offset = log(clot_denom), family = poisson))

coef2 <- coef(summary(glm.nb(clot_count ~ covid_vac + offset(log(clot_denom)), merged)))
colnames(coef2) <- c("Estimate", "Std. error", "z-value", "P-value")
kable(coef2, caption = "Negative binomial regression summary for $clot$ vs $covid\\_vac$")
```

In the above table, the summary shows that for every increase of 1% in the rate of COVID vaccinations among staff in a hospital, the logarithm of the expected number of postoperative serious blood clot events increases by 0.0033. In other words, the expected number of postoperative serious blood clot events increases by a factor of $\exp(0.0033) = 1.0033$. The P-value of the predictor is 0 < 0.001, indicating significance. The AIC of the current model (15427) is lower than the AIC of the corresponding Poisson model (19051), indicating the current model better fits the data.

Finally, for the same reasons as before, I perform negative binomial regression on `stream_count ~ staph + offset(log(total))`, where `stream_count` is the number of postoperative bloodstream infection events for each hospital, `staph` is the only significant predictor in the corresponding Poisson model (P-value = 8.27e-06 < 0.001), and `log(total)` is the offset.

```{r, echo = FALSE}
# summary(glm(data = merged, formula = stream_count ~ central_line + staph + ed_vol + covid_vac + flu_vac, offset = log(stream_denom), family = poisson))

coef3 <- coef(summary(glm.nb(stream_count ~ staph + offset(log(stream_denom)), merged)))
colnames(coef3) <- c("Estimate", "Std. error", "z-value", "P-value")
kable(coef3, caption = "Negative binomial regression summary for $stream$ vs $staph$")
```

In the above table, the summary shows that for every increase of 1% in the rate of hospital-acquired staph infections in a hospital, the logarithm of the expected number of postoperative bloodstream infections increases by 8.07. In other words, the expected number of postoperative bloodstream infections increases by a factor of $\exp(8.07) = 3195$. This regression coefficient is very large, likely because the values for `staph` in the data are very close to 0%. The P-value of the predictor is 1e-07 < 0.001, indicating significance. The AIC of the current model (12569) is lower than the AIC of the corresponding Poisson model (14139), indicating the current model better fits the data.

Overall, `flu_vac`, `covid_vac`, and `staph` are relatively significant predictors for `hem`, `clot`, and `stream` respectively, which agrees with the results of my exploratory data analysis.

## Machine learning models

```{r, echo = FALSE, fig.show = "hide"}
# Splitting data into train and test sets

set.seed(1)
train_indices <- sample(1:nrow(merged), round(0.7*nrow(merged)))
train <- merged[train_indices,]
test <- merged[-train_indices,]

# Bagging

set.seed(1)
bag1 <- randomForest(hem ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train, mtry = 5)
bag2 <- randomForest(clot ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train, mtry = 5)
bag3 <- randomForest(stream ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train, mtry = 5)

# Random forest

set.seed(1)
rf1 <- randomForest(hem ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train)
rf2 <- randomForest(clot ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train)
rf3 <- randomForest(stream ~ central_line + staph + ed_vol + covid_vac + flu_vac, data = train)

# XGBoost

set.seed(1)
tune_grid <- expand.grid(
  max_depth = c(1, 3, 5, 7), nrounds = (1:10) * 50,
  eta = c(0.001, 0.01, 0.1, 0.2), gamma = 0, subsample = 1,
  min_child_weight = 1, colsample_bytree = 0.6)

xgb1 <- caret::train(
  hem ~ central_line + staph + ed_vol + covid_vac + flu_vac,
  data = train, method = 'xgbTree',
  trControl = trainControl(method = "cv", number = 10, search = "grid"),
  tuneGrid = tune_grid, verbosity = 0)

xgb2 <- caret::train(
  clot ~ central_line + staph + ed_vol + covid_vac + flu_vac,
  data = train, method = 'xgbTree',
  trControl = trainControl(method = "cv", number = 10, search = "grid"),
  tuneGrid = tune_grid, verbosity = 0)

xgb3 <- caret::train(
  stream ~ central_line + staph + ed_vol + covid_vac + flu_vac,
  data = train, method = 'xgbTree',
  trControl = trainControl(method = "cv", number = 10, search = "grid"),
  tuneGrid = tune_grid, verbosity = 0)

# saveRDS(xgb1, "xgb1.rds")
# saveRDS(xgb2, "xgb2.rds")
# saveRDS(xgb3, "xgb3.rds")

# xgb1 <- readRDS("xgb1.rds")
# xgb2 <- readRDS("xgb2.rds")
# xgb3 <- readRDS("xgb3.rds")

imp1 <- as.data.frame(varImpPlot(bag1))
imp2 <- as.data.frame(varImpPlot(bag2))
imp3 <- as.data.frame(varImpPlot(bag3))
imp4 <- as.data.frame(varImpPlot(rf1))
imp5 <- as.data.frame(varImpPlot(rf2))
imp6 <- as.data.frame(varImpPlot(rf3))
imp7 <- varImp(xgb1)$importance
imp8 <- varImp(xgb2)$importance
imp9 <- varImp(xgb3)$importance

imp1$var_names <- rownames(imp1)
imp2$var_names <- rownames(imp2)
imp3$var_names <- rownames(imp3)
imp4$var_names <- rownames(imp4)
imp5$var_names <- rownames(imp5)
imp6$var_names <- rownames(imp6)
imp7$var_names <- rownames(imp7)
imp8$var_names <- rownames(imp8)
imp9$var_names <- rownames(imp9)
```

To answer my question using machine learning, I now create bagging, random forest, and XGBoost models for each outcome and explore their variable importance metrics. Specifically, I aim to determine whether XGBoost has better predictive accuracy compared to the other less complex models. To train the models and calculate their test MSEs, I split the data into 70% train and 30% test sets.

```{r, echo = FALSE, fig.align = 'center', out.width = "75%"}
imp1 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Bagging",
       x = "Variable", y = "Increase in node purity") +
  coord_flip() +
imp4 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Random forest",
       x = element_blank(), y = "Increase in node purity") +
  coord_flip() +
imp7 |>
  ggplot(aes(x = reorder(var_names, Overall), y = Overall)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = Overall)) +
  labs(title = "XGBoost",
       x = element_blank(), y = "Importance") +
  coord_flip() +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Variance importance for predicting the variable 'hem' using:")
```

The above plot shows that `covid_vac` is the most important variable for predicting `hem` when using bagging and random forest. In fact, `covid_vac`, `central_line`, `staph`, and `flu_vac` all have very similar levels of importance in the random forest model. Importantly, `flu_vac` is the most important variable in the XGBoost model, which agrees with my previous finding that it is a relatively significant predictor for `hem`. Despite this, `flu_vac` has lower importance in the bagging and random forest models. Finally, `ED_vol` is the least important variable for all models, which agrees with the results of my exploratory data analysis.

```{r, echo = FALSE, fig.align = 'center', out.width = "75%"}
imp2 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Bagging",
       x = "Variable", y = "Increase in node purity") +
  coord_flip() +
imp5 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Random forest",
       x = element_blank(), y = "Increase in node purity") +
  coord_flip() +
imp8 |>
  ggplot(aes(x = reorder(var_names, Overall), y = Overall)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = Overall)) +
  labs(title = "XGBoost",
       x = element_blank(), y = "Importance") +
  coord_flip() +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Variance importance for predicting the variable 'clot' using:")
```

The above plot shows that `covid_vac` is the most important variable for predicting `clot` in all models, which agrees with my previous finding that it is a relatively significant predictor for `clot`. Again, `covid_vac`, `central_line`, `staph`, and `flu_vac` all have very similar levels of importance in the random forest model, while `ED_vol` is the least important variable for all models.

```{r, echo = FALSE, fig.align = 'center', out.width = "75%"}
imp3 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Bagging",
       x = "Variable", y = "Increase in node purity") +
  coord_flip() +
imp6 |>
  ggplot(aes(x = reorder(var_names, IncNodePurity),
             y = IncNodePurity)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = IncNodePurity)) +
  labs(title = "Random forest",
       x = element_blank(), y = "Increase in node purity") +
  coord_flip() +
imp9 |>
  ggplot(aes(x = reorder(var_names, Overall), y = Overall)) +
  geom_point() +
  geom_segment(aes(x = var_names, xend = var_names,
                   y = 0, yend = Overall)) +
  labs(title = "XGBoost",
       x = element_blank(), y = "Importance") +
  coord_flip() +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Variance importance for predicting the variable 'stream' using:")
```

The above plot shows that `central_line` is the most important variable and `staph` is the second most important variable for predicting `stream` when using bagging and random forest. Interestingly, `central_line` and `staph` have very similar levels of importance in the random forest model. Importantly, `staph` is the most important variable in the XGBoost model, which agrees with my previous finding that it is a relatively significant predictor for `stream`. Again, `ED_vol` is the least important variable for all models.

Finally, I now look at the test MSEs of the models.

```{r, echo = FALSE, fig.align = 'center', out.width = "75%"}
# Plotting MSE

data.frame(Method = c("Bagging", "Random forest", "XGBoost"), 
           MSE = c(mean((predict(bag1, test) - test$hem)^2),
                   mean((predict(rf1, test) - test$hem)^2),
                   mean((predict(xgb1, test) - test$hem)^2))) |> 
  ggplot(aes(x = reorder(Method, MSE), y = MSE)) +
  geom_point() +
  geom_segment(aes(x = Method, xend = Method, y = 0, yend = MSE)) +
  labs(title = "'hem'",
       x = "Method", y = "MSE") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
data.frame(Method = c("Bagging", "Random forest", "XGBoost"), 
           MSE = c(mean((predict(bag2, test) - test$clot)^2),
                   mean((predict(rf2, test) - test$clot)^2),
                   mean((predict(xgb2, test) - test$clot)^2))) |> 
  ggplot(aes(x = reorder(Method, MSE), y = MSE)) +
  geom_point() +
  geom_segment(aes(x = Method, xend = Method, y = 0, yend = MSE)) +
  labs(title = "'clot'",
       x = element_blank(), y = "MSE") +
  coord_flip() +
data.frame(Method = c("Bagging", "Random forest", "XGBoost"), 
           MSE = c(mean((predict(bag2, test) - test$stream)^2),
                   mean((predict(rf3, test) - test$stream)^2),
                   mean((predict(xgb3, test) - test$stream)^2))) |> 
  ggplot(aes(x = reorder(Method, MSE), y = MSE)) +
  geom_point() +
  geom_segment(aes(x = Method, xend = Method, y = 0, yend = MSE)) +
  labs(title = "'stream'",
       x = element_blank(), y = "MSE") +
  coord_flip() +
  plot_layout(ncol = 3) +
  plot_annotation(title = "Test MSE for each method and outcome")
```

The above plot shows that the random forest model has the smallest MSE when predicting `hem` and `clot` on the test set, while the XGBoost model has the smallest MSE when predicting `stream` on the test set. In fact, all models have very similar MSEs when predicting `hem` and `clot`. Thus, XGBoost does not perform as well as I thought compared to the other approaches. However, it does perform significantly better than bagging when predicting `stream`, indicating an improvement in accuracy for this outcome.

Overall, random forest performs the best for predicting `hem` and `clot`, while XGBoost performs the best for predicting `stream`. In particular, the most important variables for the XGBoost models agree with the results of my regression analysis, which reinforces their significance.

# Summary

In summary, I found that rates of vaccinations among hospital staff and hospital-acquired staph infections are able to predict postoperative blood-related complication rates to some extent. Specifically, `flu_vac`, `covid_vac`, and `staph` are the most significant predictors for `hem`, `clot`, and `stream` respectively, or in other words:

- The rate of flu vaccinations among hospital staff is likely related to the rate of postoperative hemorrhage / hematoma events;

- The rate of COVID vaccinations among hospital staff is likely related to the rate of postoperative serious blood clots; and

- The rate of hospital-acquired staph infections is likely related to the rate of postoperative bloodstream infections. This relationship might be relatively strong since it has the largest corresponding regression coefficient.

These relationships are supported by my exploratory data analysis, regression analysis, and the variable importance metrics in the machine learning models. Interestingly, contrary to my initial hypothesis, the rates of vaccinations among hospital staff positively correlate with the outcomes. In addition, this correlation direction appear to be reversed when grouping by state, which makes sense for the rates of vaccinations. Despite this, my exploratory data analysis indicates that these relationships are likely generally weak. Moreover, I did not find any significant relationships between ED volume and the rest of the variables, even after applying a logarithmic transformation to the outcomes.

There are likely several limitations to my analysis, including unaddressed confounding factors. Importantly, an issue with the datasets used is that each dataset has different time periods of data collection. This means the values of interest are aggregated across different periods and may not be exactly comparable between datasets. Here, I have been assuming that the values for each hospital are similar between different time periods. However, this is a rather naive assumption and may have adversely affected my analysis. To resolve this issue, it would be helpful to be able to look at the trends in the variables across time, such as by day or month. This can be investigated with other datasets to extend this analysis in the future.

# Works cited

Brar S, McAlister FA, Youngson E, Rowe BH. 2013. Do Outcomes for Patients With Heart Failure Vary by Emergency Department Volume? Circulation: Heart Failure. 6(6): 1147–1154.

Dencker EE, Bonde A, Troelsen A, Varadarajan KM, Sillesen M. 2021. Postoperative complications: an observational study of trends in the United States from 2012 to 2018. BMC Surgery. 21(1): 1-10.

Hollmeyer H, Hayden F, Mounts A, Buchholz U. 2012. Review: interventions to increase influenza vaccination among healthcare workers in hospitals. Influenza and Other Respiratory Viruses. 7(4): 604–621.

Kanerva M, Ollgren J, Virtanen MJ, Lyytikäinen O. 2008. Risk factors for death in a cohort of patients with and without healthcare-associated infections in Finnish acute care hospitals. Journal of Hospital Infection. 70(4): 353-360.